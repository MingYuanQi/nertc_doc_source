<!--keywords:音视频通话,纯传输通道,编码后数据传输,裸流传输 -->

在一些需要与硬件配合的应用场景中，比如使用教室硬件设备进行线上教学，在利用硬件自身能力进行音频采集、编码的基础上，还需要良好的抗弱网传输能力。为了帮助拥有第三方音频编解码模块或自研编解码的开发者实现实时音频码流传输互通，NERTC SDK 为用户提供抗弱网、抗丢包的纯传输通道。

## 功能介绍

依托网易云信底层实时传输网络 WE-CAN（Communication Acceleration Network），NERTC 运用全球节点及抗弱网算法，提供低延时、高稳定性的音视频码流传输通道，大大减少延时、丢包等网络问题对音视频传输质量和体验的影响。

NERTC SDK 支持音频裸流传输，您可以向 NERTC SDK 提供自定义的 OPUS 等格式的音频编码数据，并由 NERTC SDK 进行推流。

## 注意事项

使用 NERTC SDK 提供的裸流传输通道时，您需要自行管理音频流的采集、编解码、渲染和其他处理。

## 发送音频裸流

### 实现方法

1. 在加入房间前，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#aed2eade285fb544f4bbb27b3f3af7915" target="_blank">`setExternalAudioSource`</a> 方法开启外部音频主流输入或调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#aac575f3161f150c8b2a151d9acd467fb" target="_blank">`setExternalSubStreamAudioSource`</a> 方法开启外部音频辅流输入，并设置外部音频采集参数，相关参数说明如下：
    - enabled：是否开启外部音频输入，默认关闭。
    - sample_rate：外部音频源的数据采样率，单位为赫兹（Hz）。
    - channels：外部音频源的数据声道数，可设置为单声道（1）或双声道（2）。
    ::: note note
    自定义外部音频采集接口只能在通话前调用，接口设置在通话结束后仍然有效；若您需要关闭该功能，请在下次通话前再次调用此方法关闭自定义音频采集。
    :::
2.  调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc.html#a509ef7ce4710036eb5d76d2c97f1a082" target="_blank">`enableLocalAudio`</a> 开启媒体主流传输通道或调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#adee9c69ac723cd4161f384bc13928693" target="_blank">`enableLocalSubStreamAudio`</a> 方法开启媒体辅流传输通道。
    ::: note notice
    若您开启的是外部音频主流输入，请开启对应的媒体主流传输通道，辅流同理。
    :::
3. 您需要自行处理音频数据的采集与编码。
4. 调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#ac78574d45092ea560886d8d0cc5e1b6a" target="_blank">`pushExternalAudioEncodedFrame`</a> 方法推送外部音频主流编码帧或调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#abc15d2647292e4ef1c65bfb7a0a18836" target="_blank">`pushExternalSubStreamAudioEncodedFrame`</a> 方法推送外部音频辅流编码帧，并通过 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1audio_1_1_n_e_rtc_audio_encoded_frame.html" target="_blank">`NERtcAudioEncodedFrame`</a> 设置编码后的音频数据，包括音频数据类型、数据长度、声道数、样本数等。
    ::: note notice
    建议在推送外部音频编码帧时，不要同时调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#a1a7ac62dad8784d8a0273b029be782f5" target="_blank">`pushExternalAudioFrame`</a> 或 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#a18829d74ec8ce20956cf508398a65dbf" target="_blank">`pushExternalSubStreamAudioFrame`</a> 方法。
    :::

### 示例代码

```
//发送音频主流编码后数据
//开启主流外部音频输入
NERtcEx.getInstance().setExternalAudioSource(true, sampleRate/* 采样率 */, channels/* 声道数 */);
//打开本地音频主流通道
NERtcEx.getInstance().enableLocalAudio(true);

//加入房间之后再做如下操作
NERtcAudioEncodedFrame encodedFrame = new NERtcAudioEncodedFrame();
encodedFrame.timeStampUs = 时间戳;
encodedFrame.sampleRate = 采样率;
encodedFrame.channels = 通道数;
encodedFrame.samplesPerChannel = 每个声道的样本数;
encodedFrame.encodedTimestamp = 编码时间戳;
encodedFrame.rmsLevel = 音量标记;
//数据类型，opus
encodedFrame.payloadType = NERtcAudioEncodedFrame.NERtcAudioPayLoadType.AUDIO_PAY_LOAD_TYPE_OPUS;
//推送外部音频主流编码帧
NERtcEx.getInstance().pushExternalAudioEncodedFrame(encodedFrame);

//实现发送音频辅流编码后的数据
//开启辅流外部音频输入
NERtcEx.getInstance().setExternalSubStreamAudioSource(true, sampleRate/*采样率*/, channels/*通道数*/);
//打开音频辅流视频通道
NERtcEx.getInstance().enableLocalSubStreamAudio(true);

//加入房间后再做如下操作
NERtcAudioEncodedFrame subEncodeFrame = new NERtcAudioEncodedFrame();
subEncodeFrame.timeStampUs = 时间戳;
subEncodeFrame.sampleRate = 采样率;
subEncodeFrame.channels = 通道数;
subEncodeFrame.samplesPerChannel = 每个声道的样本数;
subEncodeFrame.encodedTimestamp = 编码时间戳;
encodedFrame.rmsLevel = 音量标记;
//数据类型，opus
subEncodeFrame.payloadType = NERtcAudioEncodedFrame.NERtcAudioPayLoadType.AUDIO_PAY_LOAD_TYPE_OPUS;
//推送外部音频辅流音频帧
NERtcEx.getInstance().pushExternalSubStreamAudioFrame(subEncodeFrame);
```

## 接收音频裸流

### 实现方法

1. 在初始化后，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#a601f459db392590ba0edea86376a356b" target="_blank">`setPreDecodeObserver`</a> 注册解码前媒体数据观测器。

2. 远端发送音频流后，SDK 触发 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/interfacecom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1predecoder_1_1_n_e_rtc_pre_decode_observer.html#a91a24226449d5e6ebb8434b0ad54c9a4" target="_blank">`onFrame`</a> 回调，通过 <a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1predecoder_1_1_n_e_rtc_pre_decode_frame_info.html" target="_blank">`preDecodeFrame`</a> 参数返回相关解码前媒体数据，包括用户的 UID、媒体数据类型、数据长度、音频帧数据时间间隔等。

3. 您需要自行处理音频数据的解码与渲染。

### 示例代码

```
//设置接收裸流回调的Observer
NERtcEx.getInstance().setPreDecodeObserver(new NERtcPreDecodeObserver() {
    //在observer中实现以下回调方法，处理接收到的音频裸流数据
    @Override
    public void onFrame(NERtcPreDecodeFrameInfo preDecodeFrame) {
    }
});
```

## API 参考

| **方法** | **功能描述**|
|:--|:--|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#aed2eade285fb544f4bbb27b3f3af7915" target="_blank">`setExternalAudioSource`</a> | 开启外部音频主流输入|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#aac575f3161f150c8b2a151d9acd467fb" target="_blank">`setExternalSubStreamAudioSource`</a> |开启外部音频辅流输入|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#ac78574d45092ea560886d8d0cc5e1b6a" target="_blank">`pushExternalAudioEncodedFrame`</a> | 推送外部音频主流编码帧|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#abc15d2647292e4ef1c65bfb7a0a18836" target="_blank">`pushExternalSubStreamAudioEncodedFrame`</a> |推送外部音频辅流编码帧|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/classcom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1_n_e_rtc_ex.html#a601f459db392590ba0edea86376a356b" target="_blank">`setPreDecodeObserver`</a> |注册解码前媒体数据观测器|


| **事件** | **事件描述** |
|:--|:--|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/android/doxygen/Latest/zh/html/interfacecom_1_1netease_1_1lava_1_1nertc_1_1sdk_1_1predecoder_1_1_n_e_rtc_pre_decode_observer.html#a91a24226449d5e6ebb8434b0ad54c9a4" target="_blank">`onFrame`</a>|解码前媒体数据回调|