
NERTC SDK 支持自定义音频采集与渲染功能，可以向 NERTC SDK 提供自定义的音频输入源数据，使用自定义的渲染器，并由 NERTC SDK 进行编码推流。

一般情况下，App 采用默认设备采集音频数据，通常是本设备的内置麦克风。但在部分场景下可能需要使用自定义的音频源，例如：

- 需要使用自定义的音效或美声库、前处理库等场景。
- 需要使用外部音频源、或使用外接设备进行音频数据采集，例如在音视频通话或互动直播中播放音频文件等场景。
- App 无法获取音频采集设备的控制权限，例如音频采集设备已被其他业务占用、硬件设备的默认音频采集模块损坏等场景。

基于以上场景，NERTC SDK 支持使用自定义的音频源或渲染器，以实现业务场景中的相关需求。本文档将介绍如何实现自定义音频采集功能。

## <span id="Web自定义音频采集">自定义音频采集</span>

### **技术原理**

![采集.png](https://yx-web-nosdn.netease.im/common/e44aca2e9ce95aa35bd0824911b08fb1/采集.png)

### **实现方法**

调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/web/typedoc/Latest/zh/html/modules/nertc.nertc-1.html#createstream" target="_blank">`createStream`</a> 方法创建音频流时，可以通过 **audioSource** 指定自定义的音频输入源，以此实现自定义音频采集。

**示例代码**如下：
```
const mediaStream = await navigator.mediaDevices.getUserMedia({audio: true});
const audioSource = await mediaStream.getAudioTracks()[0];
// 自行处理音频源数据
const localStream = NERTC.createStream({
  audio: true,
  audioSource: audioSource
});
await localStream.init();
await client.publish(localStream);
```

## <span id="Web自定义音频渲染">自定义音频渲染</span>

### **实现方法**

调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/web/typedoc/Latest/zh/html/interfaces/stream.stream-1.html#getaudiostream" target="_blank">`Stream.getAudioStream`</a> 方法后，SDK 会返回一个 `MediaStream` 对象。您可以通过自行渲染这个对象实现自定义的音频渲染。

例如，将 audio dom 节点的 srcObject 属性设为该对象。

::: note notice
使用自定义音频渲染功能时，需要在播放远端流时，关闭默认的音频渲染。
:::

**示例代码**如下：
```
//播放源端音频流时，关闭默认的音频渲染
remoteStream.play({
  audio: false,
  video: true
});
const audioStream = remoteStream.getAudioStream();
// audioDom为自行创建的DOM节点
audioDom.srcObject = audioStream;
```



