<!--keywords:音视频通话,自定义音频采集,自定义音频渲染 -->

在合唱或直播场景中，用户往往需要共享非麦克风采集的外部音频源，比如希望在合唱过程中使用自定义的音乐文件。为了支持用户使用自定义音频源， NERTC SDK 为用户提供传输通道，并进行编码推流。

## 功能介绍
NERTC SDK 支持自定义音频采集与渲染功能，可以向 NERTC SDK 提供自定义的音频输入源数据，使用自定义的渲染器，并由 NERTC SDK 进行编码推流。
<br>一般情况下，App 通过本设备的内置麦克风采集音频数据。但在部分场景下可能需要使用自定义的音频源，例如：
- 需要使用自定义的音效、美声库或前处理库。
- 需要使用外部音频源或外接设备进行音频数据采集，例如在音视频通话或互动直播中播放自定义的音频文件。
- App 无法获取音频采集设备的控制权限，例如音频采集设备已被其他业务占用，或硬件设备的默认音频采集模块损坏等场景下。
<br>基于以上场景，NERTC SDK 支持使用自定义的音频源或渲染器，以实现业务场景中的相关需求。

## 注意事项

- 自定义音频采集场景中，您需要自行管理音频数据的采集和处理；自定义音频渲染场景中，您需要自行管理音频数据的处理和播放。在两种场景下，音频处理 3A 算法（AEC、ANS 和 AGC）均为关闭状态，不可手动开启。
- 通过 <a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a4c8fc3a5c133cb91a81a2493edd2ecdb" target="_blank">`PushExternalAudioFrame`</a> 接口向 SDK 投送的数据必须是 PCM 格式的未经压缩的音频裸数据，不支持其他压缩格式。

## <span id="自定义音频采集">自定义音频采集</span>

### **API 调用时序**

@startuml
!include https://raw.githubusercontent.com/bschwarz/puml-themes/master/themes/cerulean-outline/puml-theme-cerulean-outline.puml
skinparam backgroundColor #FFFFFF

应用层 -> NERtcSDK: EnableLocalAudio
应用层 -> NERtcSDK: SetExternalAudioSource
note over 应用层, NERtcSDK #FFAAAA: 自行处理音频数据
应用层 -> NERtcSDK: PushExternalAudioFrame
@enduml


### **配置步骤**
1. 在加入房间前，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a5d885296e51c0195ed1586966f01e2ec" target="_blank">`SetExternalAudioSource`</a> 方法开启外部音频主流输入，并设置外部音频采集参数，相关参数说明如下：
    - enabled：是否开启外部音频输入，默认关闭。
    - sampleRate：外部音频源的数据采样率，单位为赫兹（Hz）。
    - channels：外部音频源的数据声道数，可设置为单声道（1）或双声道（2）。
    ::: note note
    自定义外部音频采集接口仅支持在加入房间前调用，接口设置在通话结束后仍然有效；若您需要关闭该功能，请在下次通话前再次调用此方法关闭自定义音频采集。
    :::
2. 成功加入房间之后，使用自采集模块采集音频数据。您需要自行管理音频数据采集和处理逻辑。
3. 完成音频数据处理后，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a4c8fc3a5c133cb91a81a2493edd2ecdb" target="_blank">`PushExternalAudioFrame`</a> 方法将外部音频主流数据帧推送给 NERTC SDK，并设置外部音频格式。
    ::: note note
    建议推送的音频数据帧时长至少为 10 ms。
    :::

### **示例代码**

```
//开启自定义音频主流采集
private void setExternalAudioSource()
{
    //需要在入会之前设置，通话中设置无效
    int result = rtcEngine.SetExternalAudioSource(true, 48000, 1);
    if (result != (int)RtcErrorCode.kNERtcNoError)
    {
        //失败
    }
}
//推送自定义音频数据
private void pushExternalAudioFrame()
{
    //最好在高优先级线程上push音频数据，比如音频设备线程
    var frame = new RtcAudioFrame
    {
        data = IntPtr.Zero,//需要传入实际的音频buffer，不能使用IntPtr.Zero
        format = new RtcAudioFormat
        {
            type = RtcAudioType.kNERtcAudioTypePCM16,//音频 PCM 类型
            bytesPerSample = 2,//每个采样点的字节数
            samplesPerChannel = 48000 * 10,//单声道的采样点个数，假设采样周期是10 ms
            sampleRate = 4800,//音频采样率
            channels = 1,//音频声道数
        }

    };
    //push音频数据
    int result = rtcEngine.PushExternalAudioFrame(frame);
    if (result != (int)RtcErrorCode.kNERtcNoError)
    {
        //失败
    }
}

```

### <span id="API 参考">**API 参考**</span>

| **方法** | **功能描述**|
|:--|:--|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a5d885296e51c0195ed1586966f01e2ec" target="_blank">`SetExternalAudioSource`</a>|开启自定义音频主流采集|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a4c8fc3a5c133cb91a81a2493edd2ecdb" target="_blank">`PushExternalAudioFrame`</a>|将外部音频主流数据帧推送给 NERTC SDK|

## <span id="自定义音频渲染">自定义音频渲染</span>

### **API 调用时序**

@startuml
!include https://raw.githubusercontent.com/bschwarz/puml-themes/master/themes/cerulean-outline/puml-theme-cerulean-outline.puml
skinparam backgroundColor #FFFFFF

应用层 -> NERtcSDK: SetExternalAudioRender
应用层 -> NERtcSDK: PullExternalAudioFrame
note over 应用层, NERtcSDK #FFAAAA: 自行处理音频数据
@enduml

### **配置步骤**

1. 在加入房间前，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a919cbc7e64f2aff6d3595303e7831aa2" target="_blank">`SetExternalAudioRender`</a> 方法开启外部音频渲染，并设置外部音频渲染参数，相关参数的说明如下：
    - enabled：是否开启外部音频输入，默认关闭。
    - sample_rate：外部音频源的数据采样率，单位为赫兹（Hz）。
    - channels：外部音频源的数据声道数，可设置为单声道（1）或双声道（2）。
    ::: note note
    此接口设置在通话结束后后仍然有效；若您需要关闭该功能，请在下次通话前再次调用此方法关闭自定义音频渲染。
    :::
2. 成功加入房间后，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#af2a699daad176f38f3f0ad183f5e419c" target="_blank">`PullExternalAudioFrame`</a> 方法拉取远端发送的外部音频数据帧，相关参数的说明如下：
    - data：数据指针。
    - len：待拉取音频数据的字节数。该参数的单位为 byte，数据长度不能超过 7680 字节。
          <br>计算公式为： len = sampleRate/1000 × 2 × channels × 音频数据时长（ms）。
    ::: note note
    - 建议推送的音频数据帧时长至少为 10 ms。
    - 音频渲染设备关闭后，调用此方法时会返回空数据。例如在通话结束或通话前扬声器设备测试关闭等情况下，该设置不再生效。
    :::
3. 您需要自行渲染并播放拉取到的音频数据。

### **示例代码**

```C#
int sampleRate = 48000;//音频采样率
int channels = 2;//音频声道数

//开启自定义音频渲染
private void setExternalAudioRender()
{
    //需要在入会之前设置，通话中设置无效
    int result = rtcEngine.SetExternalAudioRender(true, sampleRate, channels);
    if (result != (int)RtcErrorCode.kNERtcNoError)
    {
        //失败
    }
}
//获取音频数据
private void pullExternalAudioFrame()
{
    int duration = 10;//毫秒
    int sampleLength = sampleRate * channels * duration * 2 / 1000;
    byte[] data = new byte[sampleLength];
    int result = rtcEngine.PullExternalAudioFrame(data, sampleLength);                  //音频声道数
    if (result != (int)RtcErrorCode.kNERtcNoError)
    {
        //失败
    }

    //拿到数据后可以播放
}
```

### <span id="API 参考">**API 参考**</span>

| **方法** | **功能描述**|
|:--|:--|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#a919cbc7e64f2aff6d3595303e7831aa2" target="_blank">`SetExternalAudioRender`</a>|开启外部音频渲染|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/unity/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine.html#af2a699daad176f38f3f0ad183f5e419c" target="_blank">`PullExternalAudioFrame`</a>|拉取远端发送的外部音频数据帧|