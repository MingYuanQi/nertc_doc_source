<!--keywords:音视频通话,自定义音频采集,自定义音频渲染,音频辅流 -->

在合唱或直播场景中，用户往往需要共享非麦克风采集的外部音频源，比如希望在合唱过程中使用自定义的音乐文件。为了支持用户使用自定义音频源， NERTC SDK 为用户提供传输通道，并进行编码推流。

## 功能介绍
NERTC SDK 支持自定义音频采集与渲染功能，可以向 NERTC SDK 提供自定义的音频输入源数据，使用自定义的渲染器，并由 NERTC SDK 进行编码推流。
<br>一般情况下，App 通过本设备的内置麦克风采集音频数据。但在部分场景下可能需要使用自定义的音频源，例如：
- 需要使用自定义的音效、美声库或前处理库。
- 需要使用外部音频源或外接设备进行音频数据采集，例如在音视频通话或互动直播中播放自定义的音频文件。
- App 无法获取音频采集设备的控制权限，例如音频采集设备已被其他业务占用，或硬件设备的默认音频采集模块损坏等场景下。
<br>基于以上场景，NERTC SDK 支持使用自定义的音频源或渲染器，以实现业务场景中的相关需求。

## 注意事项

- 自定义音频采集场景中，您需要自行管理音频数据的采集和处理；自定义音频渲染场景中，您需要自行管理音频数据的处理和播放。在两种场景下，音频处理 3A 算法（AEC、ANS 和 AGC）均为关闭状态，不可手动开启。
- 通过 <a href="hhttps://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a22f7611bf3d9462c03d3bf77f1e5fdb4" target="_blank">`pushExternalAudioFrame`</a> 接口向 SDK 投送的数据必须是 PCM 格式的未经压缩的音频裸数据，不支持其他压缩格式。

## <span id="自定义音频采集">自定义音频采集</span>

### **技术原理**

![采集.png](https://yx-web-nosdn.netease.im/common/322244f0139a77b23e8ba33373ef2372/采集.png)

### **API 调用时序**

![Custom_audio_source.png](https://yx-web-nosdn.netease.im/common/12bcf4f34ce5ecfa5c8ab31bb8a31e85/Custom_audio_source.png)

### **配置步骤**
1. 在加入房间前，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a32505c00824e8f85443a9e5e7a8c04f3" target="_blank">`setExternalAudioSource`</a> 方法开启外部音频主流输入，并设置外部音频采集参数，相关参数说明如下：
    - enabled：是否开启外部音频输入，默认关闭。
    - sample_rate：外部音频源的数据采样率，单位为赫兹（Hz）。
    - channels：外部音频源的数据声道数，可设置为单声道（1）或双声道（2）。
    ::: note note
    自定义外部音频采集接口仅支持在加入房间前调用，接口设置在通话结束后仍然有效；若您需要关闭该功能，请在下次通话前再次调用此方法关闭自定义音频采集。
    :::
2. 成功加入房间之后，使用自采集模块采集音频数据。您需要自行管理音频数据采集和处理逻辑。
3. 完成音频数据处理后，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a0e9b283dd7b1d3d5beb39760fb2fd4fb" target="_blank">`pushExternalAudioFrame`</a> 方法将外部音频主流数据帧推送给 NERTC SDK，并设置外部音频格式。
    ::: note note
    - 建议推送的音频数据帧时长至少为 10 ms。
    - `samples_per_channel` 指单通道的采样点个数，计算公式为 sample_rate * （time）/ 1000，其中 time 是推送给 SDK 的音频数据的时间间隔，比如一次是 20ms 的数据，则 time = 20。
    :::

### **示例代码**

```
//开启自定义音频主流采集
rtc_engine_->setExternalAudioSource(true, 48000, 1);

//push 数据
nertc::NERtcAudioFrame frame;
frame.data = (void*)(external_audioin_pcm_data); //音频数据
frame.format.type = nertc::kNERtcAudioTypePCM16; //音频 PCM 类型
frame.format.bytes_per_sample = 2;               //每个采样点的字节数
frame.format.samples_per_channel = 48000 * 10 / 1000; //单声道的采样点个数，假设采样周期是10 ms
frame.format.sample_rate = 48000;                //音频采样率
frame.format.channels = 1;                       //音频声道数
rtc_engine_->pushExternalAudioFrame(&frame);
```

### <span id="API 参考">API 参考</span>

| **方法** | **功能描述**|
|:--|:--|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a32505c00824e8f85443a9e5e7a8c04f3" target="_blank">`setExternalAudioSource`</a>|开启自定义音频主流采集|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a0e9b283dd7b1d3d5beb39760fb2fd4fb" target="_blank">`pushExternalAudioFrame`</a>|将外部音频主流数据帧推送给 NERTC SDK|

## <span id="自定义音频渲染">自定义音频渲染</span>

### **API 调用时序**

@startuml
!include https://raw.githubusercontent.com/bschwarz/puml-themes/master/themes/cerulean-outline/puml-theme-cerulean-outline.puml
skinparam backgroundColor #FFFFFF

应用层 -> NERtcSDK: setExternalAudioRender
应用层 -> NERtcSDK: pullExternalAudioFrame
note over 应用层, NERtcSDK #FFAAAA: 自行处理音频数据
@enduml

### **配置步骤**

1. 在加入房间前，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a37efd1ec3002171e754fadd46663867d" target="_blank">`setExternalAudioRender`</a> 方法开启外部音频渲染，并设置外部音频渲染参数，相关参数的说明如下：
    - enabled：是否开启外部音频输入，默认关闭。
    - sample_rate：外部音频源的数据采样率，单位为赫兹（Hz）。
    - channels：外部音频源的数据声道数，可设置为单声道（1）或双声道（2）。
    ::: note note
    此接口设置在通话结束后后仍然有效；若您需要关闭该功能，请在下次通话前再次调用此方法关闭自定义音频渲染。
    :::
2. 成功加入房间后，调用 <a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a22f7611bf3d9462c03d3bf77f1e5fdb4" target="_blank">`pullExternalAudioFrame`</a> 方法拉取远端发送的外部音频数据帧，相关参数的说明如下：
    - data：数据指针。
    - len：待拉取音频数据的字节数。该参数的单位为 byte，数据长度不能超过 7680 字节。
          <br>计算公式为： len = sampleRate/1000 × 2 × channels × 音频数据时长（ms）。
    ::: note note
    - 建议推送的音频数据帧时长至少为 10 ms。
    - 音频渲染设备关闭后，调用此方法时会返回空数据。例如在通话结束或通话前扬声器设备测试关闭等情况下，该设置不再生效。
    :::
3. 您需要自行渲染并播放拉取到的音频数据。

### **示例代码**

```
//自定义音频渲染
int sample_rate = 48000; 
int channels = 2;
nrtc_engine_->setExternalAudioRender(true, sample_rate, channels);
    
//pull 数据
int32_t duration= 10;//毫秒
int32_t sample_len = samplerate * channels* duration * 2 / 1000; 
uint8_t* data = new uint8_t[sample_len]; 
nrtc_engine_->pullExternalAudioFrame((void*)data, sample_len);

//to play audio data

if (data) {
    delete[] data;
}
```

### <span id="API 参考">API 参考</span>

| **方法** | **功能描述**|
|:--|:--|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a37efd1ec3002171e754fadd46663867d" target="_blank">`setExternalAudioRender`</a>|开启外部音频渲染|
|<a href="https://doc.yunxin.163.com/nertc/api-refer/linux/doxygen/Latest/zh/html/classnertc_1_1_i_rtc_engine_ex.html#a22f7611bf3d9462c03d3bf77f1e5fdb4" target="_blank">`pullExternalAudioFrame`</a>|拉取远端发送的外部音频数据帧|